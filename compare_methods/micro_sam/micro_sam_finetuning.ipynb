{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463a0c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ads4015/micromamba/envs/micro-sam-gpu/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage.measure import label as connected_components\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "import micro_sam.training as sam_training\n",
    "from micro_sam.automatic_segmentation import (\n",
    "    get_predictor_and_segmenter,\n",
    "    automatic_instance_segmentation,\n",
    ")\n",
    "\n",
    "# Root directory with your finetune patches\n",
    "ROOT = Path(\"/midtier/paetzollab/scratch/ads4015/data_selma3d/selma3d_finetune_patches\")\n",
    "print(\"ROOT exists:\", ROOT.exists())\n",
    "\n",
    "# NEW: where to save finetuned checkpoints and predictions\n",
    "CHECKPOINT_ROOT = Path(\"/midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_checkpoints\")\n",
    "PRED_ROOT = Path(\"/midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_preds\")\n",
    "\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "PRED_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe3ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_to_center(inst_mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For each instance ID > 0, compute distance to its center of mass.\n",
    "    Normalize to [0,1] per instance and invert so that center=1, edges=0.\n",
    "    Outside objects: 0.\n",
    "    \"\"\"\n",
    "    H, W = inst_mask.shape\n",
    "    out = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "    instance_ids = np.unique(inst_mask)\n",
    "    instance_ids = instance_ids[instance_ids != 0]\n",
    "\n",
    "    yy, xx = np.indices((H, W), dtype=np.float32)\n",
    "\n",
    "    for iid in instance_ids:\n",
    "        mask = (inst_mask == iid)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        cy, cx = ndi.center_of_mass(mask.astype(np.float32))\n",
    "        dist = np.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n",
    "\n",
    "        maxd = dist[mask].max() + 1e-6\n",
    "        dist_norm = dist / maxd  # 0..1 inside object\n",
    "        out[mask] = 1.0 - dist_norm[mask]  # 1 at center, 0 at furthest\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_distance_to_boundary(inst_mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For each instance ID > 0, compute distance transform inside the object.\n",
    "    Normalize to [0,1] per instance. Outside objects: 0.\n",
    "    \"\"\"\n",
    "    H, W = inst_mask.shape\n",
    "    out = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "    instance_ids = np.unique(inst_mask)\n",
    "    instance_ids = instance_ids[instance_ids != 0]\n",
    "\n",
    "    for iid in instance_ids:\n",
    "        mask = (inst_mask == iid)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        dist = ndi.distance_transform_edt(mask)\n",
    "        maxd = dist[mask].max() + 1e-6\n",
    "        dist_norm = dist / maxd  # 0..1 inside object\n",
    "        out[mask] = dist_norm[mask]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a28c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selma2DSliceDataset(Dataset):\n",
    "    def __init__(self, raw_label_pairs):\n",
    "        \"\"\"\n",
    "        raw_label_pairs: list of (raw_path, label_path)\n",
    "        Each raw_path is a single-channel NIfTI (e.g. *_ch0.nii.gz or *_ch1.nii.gz).\n",
    "        \"\"\"\n",
    "        self.pairs = raw_label_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_path, label_path = self.pairs[idx]\n",
    "        raw_path = Path(raw_path)\n",
    "        label_path = Path(label_path)\n",
    "\n",
    "        # --- load raw and label volumes ---\n",
    "        raw_vol = nib.load(str(raw_path)).get_fdata().astype(np.float32)\n",
    "        lab_vol = nib.load(str(label_path)).get_fdata().astype(np.float32)\n",
    "\n",
    "        assert raw_vol.shape == lab_vol.shape, f\"shape mismatch: {raw_vol.shape} vs {lab_vol.shape}\"\n",
    "        Z = raw_vol.shape[0]\n",
    "\n",
    "        # --- find a slice that contains at least one object ---\n",
    "        for _ in range(20):\n",
    "            z = np.random.randint(0, Z)\n",
    "            lab_slice = lab_vol[z]\n",
    "            if lab_slice.max() > 0:\n",
    "                break\n",
    "        else:\n",
    "            # fallback: deterministic scan\n",
    "            found = False\n",
    "            for z in range(Z):\n",
    "                lab_slice = lab_vol[z]\n",
    "                if lab_slice.max() > 0:\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                # no instances in this volume at all; pick a different pair\n",
    "                return self.__getitem__((idx + 1) % len(self.pairs))\n",
    "\n",
    "        img_slice = raw_vol[z]\n",
    "        lab_slice = lab_vol[z]\n",
    "\n",
    "        # --- instance mask (connected components) ---\n",
    "        bin_mask = (lab_slice > 0).astype(np.uint8)\n",
    "        inst_mask = connected_components(bin_mask, connectivity=1).astype(np.int32)\n",
    "\n",
    "        if inst_mask.max() == 0:\n",
    "            # no instance after CC, rare corner case\n",
    "            return self.__getitem__((idx + 1) % len(self.pairs))\n",
    "\n",
    "        # --- robust image normalization to [0,255] for SAM ---\n",
    "        p1 = np.percentile(img_slice, 1)\n",
    "        p99 = np.percentile(img_slice, 99)\n",
    "        if p99 > p1:\n",
    "            img_slice_norm = (img_slice - p1) / (p99 - p1)\n",
    "        else:\n",
    "            img_slice_norm = np.zeros_like(img_slice, dtype=np.float32)\n",
    "\n",
    "        img_slice_norm = np.clip(img_slice_norm, 0.0, 1.0)\n",
    "        img_slice_uint = (img_slice_norm * 255.0).astype(np.float32)\n",
    "\n",
    "        # --- label channels ---\n",
    "        # channel 0: instance ids\n",
    "        instance_channel = inst_mask.astype(np.float32)\n",
    "\n",
    "        # foreground mask\n",
    "        fg = (inst_mask > 0).astype(np.float32)\n",
    "\n",
    "        # distances\n",
    "        dist_center = compute_distance_to_center(inst_mask)\n",
    "        dist_boundary = compute_distance_to_boundary(inst_mask)\n",
    "\n",
    "        # mask distances and clamp to [0,1]\n",
    "        dist_center = np.clip(dist_center * fg, 0.0, 1.0)\n",
    "        dist_boundary = np.clip(dist_boundary * fg, 0.0, 1.0)\n",
    "\n",
    "        # assemble y: (4, H, W)\n",
    "        #   y[0] = instance ids (integer-valued)\n",
    "        #   y[1] = foreground (0..1)\n",
    "        #   y[2] = center distance (0..1)\n",
    "        #   y[3] = boundary distance (0..1)\n",
    "        y_np = np.stack(\n",
    "            [instance_channel, fg, dist_center, dist_boundary],\n",
    "            axis=0\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        # to torch\n",
    "        x = torch.from_numpy(img_slice_uint[None, ...])  # (1,H,W), float32 in [0,255]\n",
    "        y = torch.from_numpy(y_np)                        # (4,H,W)\n",
    "\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a9add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled volumes: 88\n",
      "vessels_patches : 40 channel-files (samples)\n",
      "cell_nucleus_patches : 25 channel-files (samples)\n",
      "c_fos_positive_patches : 4 channel-files (samples)\n",
      "amyloid_plaque_patches : 19 channel-files (samples)\n",
      "vessels_patches: total=40 -> test=2, train=30, val=8\n",
      "cell_nucleus_patches: total=25 -> test=2, train=18, val=5\n",
      "c_fos_positive_patches: total=4 -> test=2, train=1, val=1\n",
      "amyloid_plaque_patches: total=19 -> test=2, train=14, val=3\n",
      "Final sizes:\n",
      "  train: 63\n",
      "  val:   17\n",
      "  test:  8\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) COLLECT (class_name, raw_path, label_path) FOR ALL CHANNELS\n",
    "# --------------------------------------------------------\n",
    "records = []  # (class_name, raw_path, label_path)\n",
    "\n",
    "for class_dir in ROOT.iterdir():\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    class_name = class_dir.name  # e.g. \"amyloid_plaque_patches\", \"vessels_patches\"\n",
    "\n",
    "    # any channel: *_ch0.nii.gz, *_ch1.nii.gz, ... but exclude *_label.nii.gz\n",
    "    for raw_path in sorted(class_dir.glob(\"*_ch*.nii.gz\")):\n",
    "        if \"_label\" in raw_path.name:\n",
    "            continue\n",
    "        # label for this specific channel file\n",
    "        label_path = raw_path.with_name(raw_path.name.replace(\".nii.gz\", \"_label.nii.gz\"))\n",
    "        if label_path.exists():\n",
    "            records.append((class_name, raw_path, label_path))\n",
    "\n",
    "print(\"Total labeled volumes:\", len(records))\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) GROUP BY DATATYPE (class_name)\n",
    "# --------------------------------------------------------\n",
    "by_class = defaultdict(list)  # class_name -> list[(raw,label)]\n",
    "\n",
    "for cls, raw, lab in records:\n",
    "    by_class[cls].append((raw, lab))\n",
    "\n",
    "for cls, items in by_class.items():\n",
    "    print(cls, \":\", len(items), \"channel-files (samples)\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) STRATIFIED SPLIT:\n",
    "#    - 2 TEST samples per datatype\n",
    "#    - Remaining -> 80/20 TRAIN/VAL (per datatype)\n",
    "#    - Ensure train & val each get >=1 sample per datatype where possible\n",
    "# --------------------------------------------------------\n",
    "train_pairs = []\n",
    "val_pairs = []\n",
    "test_pairs = []\n",
    "\n",
    "for cls, items in by_class.items():\n",
    "    items = items.copy()\n",
    "    rng.shuffle(items)\n",
    "\n",
    "    if len(items) < 4:\n",
    "        raise ValueError(\n",
    "            f\"Not enough samples in class '{cls}' to hold out 2 test and still have train+val.\"\n",
    "        )\n",
    "\n",
    "    # 2 test samples for this datatype\n",
    "    test_cls = items[:2]\n",
    "    rest = items[2:]\n",
    "\n",
    "    n_rest = len(rest)\n",
    "    # initial 80/20 split\n",
    "    n_train = int(round(0.8 * n_rest))\n",
    "    # ensure at least 1 val and 1 train\n",
    "    if n_train < 1:\n",
    "        n_train = 1\n",
    "    if n_train > n_rest - 1:\n",
    "        n_train = n_rest - 1\n",
    "    n_val = n_rest - n_train\n",
    "\n",
    "    train_cls = rest[:n_train]\n",
    "    val_cls = rest[n_train:]\n",
    "\n",
    "    print(\n",
    "        f\"{cls}: total={len(items)} -> test={len(test_cls)}, \"\n",
    "        f\"train={len(train_cls)}, val={len(val_cls)}\"\n",
    "    )\n",
    "\n",
    "    test_pairs.extend(test_cls)\n",
    "    train_pairs.extend(train_cls)\n",
    "    val_pairs.extend(val_cls)\n",
    "\n",
    "# Shuffle globally\n",
    "rng.shuffle(train_pairs)\n",
    "rng.shuffle(val_pairs)\n",
    "rng.shuffle(test_pairs)\n",
    "\n",
    "print(\"Final sizes:\")\n",
    "print(\"  train:\", len(train_pairs))\n",
    "print(\"  val:  \", len(val_pairs))\n",
    "print(\"  test: \", len(test_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8815f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example mapping entries (first 5):\n",
      "vessels_patches -> /midtier/paetzollab/scratch/ads4015/data_selma3d/selma3d_finetune_patches/vessels_patches/patch_000_vol019_ch0.nii.gz\n",
      "vessels_patches -> /midtier/paetzollab/scratch/ads4015/data_selma3d/selma3d_finetune_patches/vessels_patches/patch_000_vol019_ch1.nii.gz\n",
      "vessels_patches -> /midtier/paetzollab/scratch/ads4015/data_selma3d/selma3d_finetune_patches/vessels_patches/patch_001_vol021_ch0.nii.gz\n",
      "vessels_patches -> /midtier/paetzollab/scratch/ads4015/data_selma3d/selma3d_finetune_patches/vessels_patches/patch_001_vol021_ch1.nii.gz\n",
      "vessels_patches -> /midtier/paetzollab/scratch/ads4015/data_selma3d/selma3d_finetune_patches/vessels_patches/patch_002_vol018_ch0.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Map each raw_path to its datatype (class_name)\n",
    "cls_by_raw = {Path(raw): cls for cls, raw, lab in records}\n",
    "\n",
    "print(\"Example mapping entries (first 5):\")\n",
    "for i, (raw, cls) in enumerate(cls_by_raw.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(cls, \"->\", raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebad6980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 63 Val samples: 17\n",
      "Held-out test samples: 8\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Selma2DSliceDataset(train_pairs)\n",
    "val_dataset = Selma2DSliceDataset(val_pairs)\n",
    "\n",
    "batch_size = 1  # keep small for microSAM\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# microSAM's JointSamTrainer expects these attributes\n",
    "train_loader.shuffle = True\n",
    "val_loader.shuffle = False\n",
    "\n",
    "print(\"Train samples:\", len(train_dataset), \"Val samples:\", len(val_dataset))\n",
    "print(\"Held-out test samples:\", len(test_pairs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449e6b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying labels in 'train' dataloader: 100%|██████████| 50/50 [00:00<00:00, 61.66it/s]\n",
      "Verifying labels in 'val' dataloader:  34%|███▍      | 17/50 [00:00<00:00, 49.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting for 630 iterations /  10 epochs\n",
      "with 63 iterations per epoch\n",
      "Training with mixed precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: average [s/it]: 0.441256, current metric: 0.238749, best metric: 0.238749: 100%|█████████▉| 629/630 [05:51<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training after 10 epochs / 630 iterations.\n",
      "The best epoch is number 9.\n",
      "Training took 354.7764194011688 seconds (= 00:05:55 hours)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "n_objects_per_batch = 5\n",
    "train_instance_segmentation = True\n",
    "model_type = \"vit_b_lm\"  # must match when loading later\n",
    "\n",
    "checkpoint_name = \"selma3d_microsam_ais\"\n",
    "# root_dir is no longer needed for checkpoints\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "sam_training.train_sam(\n",
    "    name=checkpoint_name,\n",
    "    save_root=str(CHECKPOINT_ROOT),  # <-- save into your finetuned_checkpoints dir\n",
    "    model_type=model_type,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=n_epochs,\n",
    "    n_objects_per_batch=n_objects_per_batch,\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    device=device,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57ada95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: /midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_checkpoints/checkpoints/selma3d_microsam_ais/best.pt exists: True\n"
     ]
    }
   ],
   "source": [
    "checkpoint_name = \"selma3d_microsam_ais\"\n",
    "best_checkpoint = str(\n",
    "    CHECKPOINT_ROOT / \"checkpoints\" / checkpoint_name / \"best.pt\"\n",
    ")\n",
    "print(\"Best checkpoint:\", best_checkpoint, \"exists:\", os.path.exists(best_checkpoint))\n",
    "\n",
    "\n",
    "predictor, segmenter = get_predictor_and_segmenter(\n",
    "    model_type=model_type,\n",
    "    checkpoint=best_checkpoint,\n",
    "    device=device,\n",
    "    is_tiled=False,  # we will handle tiling for large images ourselves\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628ceafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_slice_2d(predictor, segmenter, img2d, tile_shape=None, halo=None, verbose=False):\n",
    "    \"\"\"Run AIS on a single 2D slice.\"\"\"\n",
    "    img2d = img2d.astype(np.float32)\n",
    "\n",
    "    # normalize to [0,255] similarly to training\n",
    "    p1 = np.percentile(img2d, 1)\n",
    "    p99 = np.percentile(img2d, 99)\n",
    "    if p99 > p1:\n",
    "        img2d = (img2d - p1) / (p99 - p1)\n",
    "    else:\n",
    "        img2d = np.zeros_like(img2d)\n",
    "    img2d = np.clip(img2d, 0.0, 1.0)\n",
    "    img2d = (img2d * 255.0).astype(np.float32)\n",
    "\n",
    "    instances = automatic_instance_segmentation(\n",
    "        predictor=predictor,\n",
    "        segmenter=segmenter,\n",
    "        input_path=img2d,\n",
    "        ndim=2,\n",
    "        tile_shape=tile_shape,\n",
    "        halo=halo,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    return instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caef9d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_volume_slices(predictor, segmenter, vol, tile_shape=None, halo=None, verbose=False):\n",
    "    \"\"\"\n",
    "    vol: numpy array (Z, Y, X)\n",
    "    returns: instances (Z, Y, X) with per-slice instance labels.\n",
    "    \"\"\"\n",
    "    Z, Y, X = vol.shape\n",
    "    instances_vol = np.zeros((Z, Y, X), dtype=np.int32)\n",
    "\n",
    "    for z in range(Z):\n",
    "        if verbose:\n",
    "            print(f\"Segmenting slice {z+1}/{Z}...\")\n",
    "        img2d = vol[z]\n",
    "        seg2d = segment_slice_2d(\n",
    "            predictor,\n",
    "            segmenter,\n",
    "            img2d,\n",
    "            tile_shape=tile_shape,\n",
    "            halo=halo,\n",
    "            verbose=False,\n",
    "        )\n",
    "        instances_vol[z] = seg2d.astype(np.int32)\n",
    "\n",
    "    return instances_vol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdc6d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_binary_metrics(gt, pred):\n",
    "    \"\"\"Compute Dice and IoU for binary masks (numpy arrays of 0/1).\"\"\"\n",
    "    gt = gt.astype(bool)\n",
    "    pred = pred.astype(bool)\n",
    "\n",
    "    intersection = np.logical_and(gt, pred).sum()\n",
    "    union = np.logical_or(gt, pred).sum()\n",
    "    gt_sum = gt.sum()\n",
    "    pred_sum = pred.sum()\n",
    "\n",
    "    # Dice\n",
    "    denom = gt_sum + pred_sum\n",
    "    dice = 2.0 * intersection / denom if denom > 0 else np.nan\n",
    "\n",
    "    # IoU\n",
    "    iou = intersection / union if union > 0 else np.nan\n",
    "\n",
    "    return dice, iou\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a851b64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating patch_016_vol008_ch0.nii.gz (class=vessels_patches)\n",
      "  Saved prediction to: /midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_preds/vessels_patches/patch_016_vol008_ch0_microsam_ais2dstack.nii.gz\n",
      "Evaluating patch_010_vol000_ch0.nii.gz (class=cell_nucleus_patches)\n",
      "  Saved prediction to: /midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_preds/cell_nucleus_patches/patch_010_vol000_ch0_microsam_ais2dstack.nii.gz\n",
      "Evaluating patch_013_vol001_ch0.nii.gz (class=cell_nucleus_patches)\n",
      "  Saved prediction to: /midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_preds/cell_nucleus_patches/patch_013_vol001_ch0_microsam_ais2dstack.nii.gz\n",
      "Evaluating patch_011_vol019_ch0.nii.gz (class=amyloid_plaque_patches)\n",
      "  Saved prediction to: /midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_preds/amyloid_plaque_patches/patch_011_vol019_ch0_microsam_ais2dstack.nii.gz\n",
      "Evaluating patch_000_vol009_ch0.nii.gz (class=c_fos_positive_patches)\n",
      "  Saved prediction to: /midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_preds/c_fos_positive_patches/patch_000_vol009_ch0_microsam_ais2dstack.nii.gz\n",
      "Evaluating patch_003_vol023_ch1.nii.gz (class=vessels_patches)\n",
      "  Saved prediction to: /midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_preds/vessels_patches/patch_003_vol023_ch1_microsam_ais2dstack.nii.gz\n",
      "Evaluating patch_003_vol008_ch0.nii.gz (class=c_fos_positive_patches)\n",
      "  Saved prediction to: /midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_preds/c_fos_positive_patches/patch_003_vol008_ch0_microsam_ais2dstack.nii.gz\n",
      "Evaluating patch_004_vol030_ch0.nii.gz (class=amyloid_plaque_patches)\n",
      "  Saved prediction to: /midtier/paetzollab/scratch/ads4015/compare_methods/micro_sam/finetuned_preds/amyloid_plaque_patches/patch_004_vol030_ch0_microsam_ais2dstack.nii.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>raw_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>pred_path</th>\n",
       "      <th>mean_dice</th>\n",
       "      <th>mean_iou</th>\n",
       "      <th>n_slices_with_fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vessels_patches</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/compare_me...</td>\n",
       "      <td>0.812819</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cell_nucleus_patches</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/compare_me...</td>\n",
       "      <td>0.060692</td>\n",
       "      <td>0.034644</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cell_nucleus_patches</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/compare_me...</td>\n",
       "      <td>0.236245</td>\n",
       "      <td>0.140939</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amyloid_plaque_patches</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/compare_me...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_fos_positive_patches</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/compare_me...</td>\n",
       "      <td>0.129663</td>\n",
       "      <td>0.077383</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vessels_patches</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/compare_me...</td>\n",
       "      <td>0.564281</td>\n",
       "      <td>0.398104</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c_fos_positive_patches</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/compare_me...</td>\n",
       "      <td>0.186658</td>\n",
       "      <td>0.109517</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amyloid_plaque_patches</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/data_selma...</td>\n",
       "      <td>/midtier/paetzollab/scratch/ads4015/compare_me...</td>\n",
       "      <td>0.595893</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    class                                           raw_path  \\\n",
       "0         vessels_patches  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "1    cell_nucleus_patches  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "2    cell_nucleus_patches  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "3  amyloid_plaque_patches  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "4  c_fos_positive_patches  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "5         vessels_patches  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "6  c_fos_positive_patches  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "7  amyloid_plaque_patches  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "\n",
       "                                          label_path  \\\n",
       "0  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "1  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "2  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "3  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "4  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "5  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "6  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "7  /midtier/paetzollab/scratch/ads4015/data_selma...   \n",
       "\n",
       "                                           pred_path  mean_dice  mean_iou  \\\n",
       "0  /midtier/paetzollab/scratch/ads4015/compare_me...   0.812819  0.686667   \n",
       "1  /midtier/paetzollab/scratch/ads4015/compare_me...   0.060692  0.034644   \n",
       "2  /midtier/paetzollab/scratch/ads4015/compare_me...   0.236245  0.140939   \n",
       "3  /midtier/paetzollab/scratch/ads4015/compare_me...   0.040000  0.022222   \n",
       "4  /midtier/paetzollab/scratch/ads4015/compare_me...   0.129663  0.077383   \n",
       "5  /midtier/paetzollab/scratch/ads4015/compare_me...   0.564281  0.398104   \n",
       "6  /midtier/paetzollab/scratch/ads4015/compare_me...   0.186658  0.109517   \n",
       "7  /midtier/paetzollab/scratch/ads4015/compare_me...   0.595893  0.494006   \n",
       "\n",
       "   n_slices_with_fg  \n",
       "0                96  \n",
       "1                96  \n",
       "2                96  \n",
       "3                 5  \n",
       "4                96  \n",
       "5                96  \n",
       "6                96  \n",
       "7                60  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Per-class mean metrics on held-out test set ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_dice</th>\n",
       "      <th>mean_iou</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vessels_patches</th>\n",
       "      <td>0.688550</td>\n",
       "      <td>0.542386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amyloid_plaque_patches</th>\n",
       "      <td>0.317947</td>\n",
       "      <td>0.258114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_fos_positive_patches</th>\n",
       "      <td>0.158160</td>\n",
       "      <td>0.093450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_nucleus_patches</th>\n",
       "      <td>0.148468</td>\n",
       "      <td>0.087792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean_dice  mean_iou\n",
       "class                                      \n",
       "vessels_patches          0.688550  0.542386\n",
       "amyloid_plaque_patches   0.317947  0.258114\n",
       "c_fos_positive_patches   0.158160  0.093450\n",
       "cell_nucleus_patches     0.148468  0.087792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Overall macro-average metrics over all test volumes ===\n",
      "mean_dice    0.328281\n",
      "mean_iou     0.245435\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# EVALUATE ON HELD-OUT TEST SET AND SAVE PREDICTIONS\n",
    "# ---------------------------------------------------------------------\n",
    "results = []  # per-volume metrics\n",
    "\n",
    "eval_tile_shape = None  # fine for 96x96 patches\n",
    "eval_halo = None\n",
    "\n",
    "for raw_path, label_path in test_pairs:\n",
    "    raw_path = Path(raw_path)\n",
    "    label_path = Path(label_path)\n",
    "\n",
    "    cls = cls_by_raw[raw_path]\n",
    "\n",
    "    print(f\"Evaluating {raw_path.name} (class={cls})\")\n",
    "\n",
    "    # load full volumes\n",
    "    raw_vol = nib.load(str(raw_path)).get_fdata().astype(np.float32)\n",
    "    lab_vol = nib.load(str(label_path)).get_fdata().astype(np.float32)\n",
    "\n",
    "    # run AIS slice-wise over the full volume\n",
    "    instances = segment_volume_slices(\n",
    "        predictor,\n",
    "        segmenter,\n",
    "        raw_vol,\n",
    "        tile_shape=eval_tile_shape,\n",
    "        halo=eval_halo,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # --- SAVE PREDICTION ---\n",
    "    cls_dir = PRED_ROOT / cls\n",
    "    cls_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pred_fname = raw_path.name.replace(\".nii.gz\", \"_microsam_ais2dstack.nii.gz\")\n",
    "    pred_path = cls_dir / pred_fname\n",
    "\n",
    "    pred_nii = nib.Nifti1Image(instances.astype(np.int32), affine=nib.load(str(raw_path)).affine)\n",
    "    nib.save(pred_nii, pred_path)\n",
    "    print(f\"  Saved prediction to: {pred_path}\")\n",
    "\n",
    "    # --- COMPUTE SLICE-WISE DICE/IOU (BINARY FOREGROUND) ---\n",
    "    Z = raw_vol.shape[0]\n",
    "    dice_list = []\n",
    "    iou_list = []\n",
    "\n",
    "    for z in range(Z):\n",
    "        gt_slice = lab_vol[z]\n",
    "        if gt_slice.max() == 0:\n",
    "            # skip slices without any foreground in GT\n",
    "            continue\n",
    "\n",
    "        pred_slice = instances[z]\n",
    "\n",
    "        gt_bin = (gt_slice > 0).astype(np.uint8)\n",
    "        pred_bin = (pred_slice > 0).astype(np.uint8)\n",
    "\n",
    "        dice, iou = compute_binary_metrics(gt_bin, pred_bin)\n",
    "        if not np.isnan(dice):\n",
    "            dice_list.append(dice)\n",
    "        if not np.isnan(iou):\n",
    "            iou_list.append(iou)\n",
    "\n",
    "    if len(dice_list) == 0:\n",
    "        mean_dice = np.nan\n",
    "        mean_iou = np.nan\n",
    "    else:\n",
    "        mean_dice = float(np.mean(dice_list))\n",
    "        mean_iou = float(np.mean(iou_list))\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"class\": cls,\n",
    "            \"raw_path\": str(raw_path),\n",
    "            \"label_path\": str(label_path),\n",
    "            \"pred_path\": str(pred_path),\n",
    "            \"mean_dice\": mean_dice,\n",
    "            \"mean_iou\": mean_iou,\n",
    "            \"n_slices_with_fg\": len(dice_list),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Aggregate into a table: per-volume + per-class + overall\n",
    "# ---------------------------------------------------------------------\n",
    "df = pd.DataFrame(results)\n",
    "display(df)\n",
    "\n",
    "per_class = (\n",
    "    df.groupby(\"class\")[[\"mean_dice\", \"mean_iou\"]]\n",
    "    .mean()\n",
    "    .sort_values(\"mean_dice\", ascending=False)\n",
    ")\n",
    "print(\"\\n=== Per-class mean metrics on held-out test set ===\")\n",
    "display(per_class)\n",
    "\n",
    "overall = df[[\"mean_dice\", \"mean_iou\"]].mean()\n",
    "print(\"\\n=== Overall macro-average metrics over all test volumes ===\")\n",
    "print(overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ad96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e031af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = str(\n",
    "#     \"/midtier/paetzollab/scratch/ads4015/data_selma3d/selma3d_finetune_patches/vessels_patches/patch_001_vol021_ch1.nii.gz\"\n",
    "# )\n",
    "\n",
    "# nii = nib.load(test_path)\n",
    "# vol = nii.get_fdata().astype(np.float32)  # (Z, Y, X)\n",
    "\n",
    "# instances = segment_volume_slices(\n",
    "#     predictor,\n",
    "#     segmenter,\n",
    "#     vol,\n",
    "#     tile_shape=None,  # no tiling needed for 96^3 patches\n",
    "#     halo=None,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# print(\"Instances shape:\", instances.shape)\n",
    "# print(\"Unique labels (first 10):\", np.unique(instances)[:10])\n",
    "\n",
    "# out_path = test_path.replace(\".nii.gz\", \"_microsam_ais2dstack.nii.gz\")\n",
    "# out_nii = nib.Nifti1Image(instances.astype(np.int32), affine=nii.affine, header=nii.header)\n",
    "# nib.save(out_nii, out_path)\n",
    "# print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50cabc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam-gpu",
   "language": "python",
   "name": "micro-sam-gpu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
