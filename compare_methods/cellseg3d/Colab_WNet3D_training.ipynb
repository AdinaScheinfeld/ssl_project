{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AdaptiveMotorControlLab/CellSeg3d/blob/main/notebooks/Colab_WNet3D_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTUVNXX7R3Go"
   },
   "source": [
    "# **WNet3D: self-supervised 3D cell segmentation**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is part of the [CellSeg3D project](https://github.com/AdaptiveMotorControlLab/CellSeg3d) in the [Mathis Lab of Adaptive Intelligence](https://www.mackenziemathislab.org/).\n",
    "\n",
    "- ðŸ’œ The foundation of this notebook owes much to the **[ZeroCostDL4Mic](https://github.com/HenriquesLab/ZeroCostDL4Mic)** project and to the **[DeepLabCut](https://github.com/DeepLabCut/DeepLabCut)** team for bringing Colab into scientific open software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmVCksV0EfVT"
   },
   "source": [
    "#**1. Installing dependencies**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "td_vf_pneSak"
   },
   "outputs": [],
   "source": [
    "# #@markdown ##Play to install CellSeg3D and WNet3D dependencies:\n",
    "# !pip install -q napari-cellseg3d\n",
    "# print(\"Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqctRognFGDT"
   },
   "source": [
    "##**1.2 Load key dependencies**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOOhJjkxjXz-",
    "outputId": "8f94416d-a482-4ec6-f980-a728e908d90d"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from pathlib import Path\n",
    "from napari_cellseg3d.dev_scripts import colab_training as c\n",
    "from napari_cellseg3d.config import WNetTrainingWorkerConfig, WandBConfig, WeightsInfo, PRETRAINED_WEIGHTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax-vJAWRwIKi"
   },
   "source": [
    "## Optional - *1.3 Initialize Weights & Biases integration*\n",
    "---\n",
    "If you wish to utilize Weights & Biases (WandB) for monitoring and logging your training session, uncomment and execute the cell below.\n",
    "To enable it, just input your API key in the space provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNgC3awjwb7G"
   },
   "outputs": [],
   "source": [
    "# !pip install -q wandb\n",
    "# import wandb\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi9gRBHFFyX-"
   },
   "source": [
    "# **2. Complete the Colab session**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSU-LYTfFnvF"
   },
   "source": [
    "\n",
    "## **2.1. Check for GPU access**\n",
    "---\n",
    "\n",
    "By default, this session is configured to use Python 3 and GPU acceleration. To verify or adjust these settings:\n",
    "\n",
    "<font size = 4>Navigate to Runtime and select Change the Runtime type.\n",
    "\n",
    "<font size = 4>For Runtime type, ensure it's set to Python 3 (the programming language this program is written in).\n",
    "\n",
    "<font size = 4>Under Accelerator, choose GPU (Graphics Processing Unit).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ie7bXiMgFtPH",
    "outputId": "3276444c-5109-47b4-f507-ea9acaab15ad"
   },
   "outputs": [],
   "source": [
    "#@markdown ##Execute the cell below to verify if GPU access is available.\n",
    "\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "  print('You do not have GPU access.')\n",
    "  print('Did you change your runtime?')\n",
    "  print('If the runtime setting is correct then Google did not allocate a GPU for your session')\n",
    "  print('Expect slow performance. To access GPU try reconnecting later')\n",
    "\n",
    "else:\n",
    "  print('You have GPU access')\n",
    "  !nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_bbk7RAF2yw"
   },
   "source": [
    "## **2.2. Mount Google Drive**\n",
    "---\n",
    "<font size = 4>To integrate this notebook with your personal data, save your data on Google Drive in accordance with the directory structures detailed in Section 0.\n",
    "\n",
    "1. <font size = 4> **Run** the **cell** below and click on the provided link.\n",
    "\n",
    "2. <font size = 4>Log in to your Google account and grant the necessary permissions by clicking 'Allow'.\n",
    "\n",
    "3. <font size = 4>Copy the generated authorization code and paste it into the cell, then press 'Enter'. This grants Colab access to read and write data to your Google Drive.\n",
    "\n",
    "4. <font size = 4> After completion, you can view your data in the notebook. Simply click the Files tab on the top left and select 'Refresh'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsIARCablq1V",
    "outputId": "77ffdbd1-4c89-4a56-e3da-7777a607a328"
   },
   "outputs": [],
   "source": [
    "# # mount user's Google Drive to Google Colab.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6FI22lkQLTv"
   },
   "source": [
    "**<font size = 4> If you cannot see your files, reactivate your session by connecting to your hosted runtime.**\n",
    "\n",
    "\n",
    "<img width=\"40%\" alt =\"Example of image detection with retinanet.\" src=\"https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/connect_to_hosted.png\"><figcaption> Connect to a hosted runtime. </figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkOpxYjaGM0m"
   },
   "source": [
    "# **3. Select your parameters and paths**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65FhTkYlGKRt"
   },
   "source": [
    "## **3.1. Choosing parameters**\n",
    "\n",
    "---\n",
    "\n",
    "### **Paths to the training data and model**\n",
    "\n",
    "* <font size = 4>**`training_source`** specifies the paths to the training data. They must be a single multipage TIF file each\n",
    "\n",
    "* <font size = 4>**`model_save_path`** specifies the directory where the model checkpoints will be saved.\n",
    "\n",
    "<font size = 4>**Tip:** To easily copy paths, navigate to the 'Files' tab, right-click on a folder or file, and choose 'Copy path'.\n",
    "\n",
    "### **Training parameters**\n",
    "\n",
    "* <font size = 4>**`number_of_epochs`** is the number of times the entire training data will be seen by the model. Default: 50\n",
    "\n",
    "* <font size = 4>**`batchs_size`** is the number of image that will be bundled together at each training step. Default: 4\n",
    "\n",
    "* <font size = 4>**`learning_rate`** is the step size of the update of the model's weight. Try decreasing it if the NCuts loss is unstable. Default: 2e-5\n",
    "\n",
    "* <font size = 4>**`num_classes`** is the number of brightness clusters to segment the image in. Try raising it to 3 if you have artifacts or \"halos\" around your cells that have significantly different brightness. Default: 2\n",
    "\n",
    "* <font size = 4>**`weight_decay`** is a regularization parameter used to prevent overfitting. Default: 0.01\n",
    "\n",
    "* <font size = 4>**`validation_frequency`** is the frequency at which the provided evaluation data is used to estimate the model's performance.\n",
    "\n",
    "* <font size = 4>**`intensity_sigma`** is the standard deviation of the feature similarity term. Default: 1\n",
    "\n",
    "* <font size = 4>**`spatial_sigma`** is the standard deviation of the spatial proximity term. Default: 4\n",
    "\n",
    "* <font size = 4>**`ncuts_radius`** is the radius for the NCuts loss computation, in pixels. Default: 2\n",
    "\n",
    "* <font size = 4>**`rec_loss`** is the loss to use for the decoder. Can be Mean Square Error (MSE) or Binary Cross Entropy (BCE). Default : MSE\n",
    "\n",
    "* <font size = 4>**`n_cuts_weight`** is the weight of the NCuts loss in the weighted sum for the backward pass. Default: 0.5\n",
    "* <font size = 4>**`rec_loss_weight`** is the weight of the reconstruction loss. Default: 0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tTSCC6ChGuuA"
   },
   "outputs": [],
   "source": [
    "#@markdown ###Path to the training data:\n",
    "training_source = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/train\" #@param {type:\"string\"}\n",
    "#@markdown ###Path to save the weights (make sure to have enough space in your drive):\n",
    "model_save_path = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints\" #@param {type:\"string\"}\n",
    "#@markdown ---\n",
    "#@markdown ###Perform validation on a test dataset (optional):\n",
    "do_validation = False #@param {type:\"boolean\"}\n",
    "#@markdown ###Path to evaluation data (optional, use if checked above):\n",
    "eval_source = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/val/vol\" #@param {type:\"string\"}\n",
    "eval_target = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/val/lab\" #@param {type:\"string\"}\n",
    "#@markdown ---\n",
    "#@markdown ###Training parameters\n",
    "number_of_epochs = 50 #@param {type:\"number\"}\n",
    "#@markdown ###Default advanced parameters\n",
    "use_default_advanced_parameters = False #@param {type:\"boolean\"}\n",
    "#@markdown <font size = 4>If not, please change:\n",
    "\n",
    "#@markdown <font size = 3>Training parameters:\n",
    "batch_size =  4 #@param {type:\"number\"}\n",
    "learning_rate = 2e-5 #@param {type:\"number\"}\n",
    "num_classes = 2 #@param {type:\"number\"}\n",
    "weight_decay = 0.01 #@param {type:\"number\"}\n",
    "#@markdown <font size = 3>Validation parameters:\n",
    "validation_frequency = 2 #@param {type:\"number\"}\n",
    "#@markdown <font size = 3>SoftNCuts parameters:\n",
    "intensity_sigma = 1.0 #@param {type:\"number\"}\n",
    "spatial_sigma = 4.0 #@param {type:\"number\"}\n",
    "ncuts_radius = 2 #@param {type:\"number\"}\n",
    "#@markdown <font size = 3>Reconstruction loss:\n",
    "rec_loss = \"MSE\" #@param[\"MSE\", \"BCE\"]\n",
    "#@markdown <font size = 3>Weighted sum of losses:\n",
    "n_cuts_weight = 0.5 #@param {type:\"number\"}\n",
    "rec_loss_weight = 0.005 #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtoIo5GcKIXX"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arWhMU6aKsri"
   },
   "source": [
    "# **4. Train the network**\n",
    "---\n",
    "\n",
    "<font size = 4>Important Reminder: Google Colab imposes a maximum session time to prevent extended GPU usage, such as for data mining. Ensure your training duration stays under 12 hours. If your training is projected to exceed this limit, consider reducing the `number_of_epochs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L59J90S_Kva3"
   },
   "source": [
    "## **4.1. Initialize the config**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOgLyUwPjvUX"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "train_data_folder = Path(training_source)\n",
    "results_path = Path(model_save_path)\n",
    "results_path.mkdir(exist_ok=True)\n",
    "eval_image_folder = Path(eval_source)\n",
    "eval_label_folder = Path(eval_target)\n",
    "\n",
    "eval_dict = c.create_eval_dataset_dict(\n",
    "        eval_image_folder,\n",
    "        eval_label_folder,\n",
    "    ) if do_validation else None\n",
    "\n",
    "try:\n",
    "  import wandb\n",
    "  WANDB_INSTALLED = True\n",
    "except ImportError:\n",
    "  WANDB_INSTALLED = False\n",
    "\n",
    "\n",
    "train_config = WNetTrainingWorkerConfig(\n",
    "    device=\"cuda:0\",\n",
    "    max_epochs=number_of_epochs,\n",
    "    learning_rate=2e-5,\n",
    "    validation_interval=2,\n",
    "    batch_size=4,\n",
    "    num_workers=2,\n",
    "    weights_info=WeightsInfo(),\n",
    "    results_path_folder=str(results_path),\n",
    "    train_data_dict=c.create_dataset_dict_no_labs(train_data_folder),\n",
    "    eval_volume_dict=eval_dict,\n",
    ") if use_default_advanced_parameters else WNetTrainingWorkerConfig(\n",
    "    device=\"cuda:0\",\n",
    "    max_epochs=number_of_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    validation_interval=validation_frequency,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    "    weights_info=WeightsInfo(),\n",
    "    results_path_folder=str(results_path),\n",
    "    train_data_dict=c.create_dataset_dict_no_labs(train_data_folder),\n",
    "    eval_volume_dict=eval_dict,\n",
    "    # advanced\n",
    "    num_classes=num_classes,\n",
    "    weight_decay=weight_decay,\n",
    "    intensity_sigma=intensity_sigma,\n",
    "    spatial_sigma=spatial_sigma,\n",
    "    radius=ncuts_radius,\n",
    "    reconstruction_loss=rec_loss,\n",
    "    n_cuts_weight=n_cuts_weight,\n",
    "    rec_loss_weight=rec_loss_weight,\n",
    ")\n",
    "wandb_config = WandBConfig(\n",
    "    mode=\"disabled\" if not WANDB_INSTALLED else \"online\",\n",
    "    save_model_artifact=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idowGpeQPIm2"
   },
   "source": [
    "## **4.2. Start training**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXxKZhGMqguz"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "worker = c.get_colab_worker(worker_config=train_config, wandb_config=wandb_config)\n",
    "for epoch_loss in worker.train():\n",
    "  continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you have trained the model, you will have the weights as a .pth file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt for Selma data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tiff dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 patches\n",
      "Train=19  Val=4  Test=2\n",
      "Saved split info â†’ /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/splits_cell_nucleus.csv\n",
      "TIF dataset ready.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tifffile as tiff\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# ----------------------------\n",
    "# Paths\n",
    "# ----------------------------\n",
    "nii_root = Path(\"/midtier/paetzollab/scratch/ads4015/data_selma3d/selma3d_finetune_patches/cell_nucleus_patches\")\n",
    "base_out = Path(\"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning\")\n",
    "tif_root = base_out / \"tif_data\"\n",
    "\n",
    "splits = {\n",
    "    \"train\": (tif_root / \"train\" / \"vol\", tif_root / \"train\" / \"lab\"),\n",
    "    \"val\":   (tif_root / \"val\" / \"vol\",   tif_root / \"val\" / \"lab\"),\n",
    "    \"test\":  (tif_root / \"test\" / \"vol\",  tif_root / \"test\" / \"lab\"),\n",
    "}\n",
    "\n",
    "# Make dirs\n",
    "for vol_dir, lab_dir in splits.values():\n",
    "    vol_dir.mkdir(parents=True, exist_ok=True)\n",
    "    lab_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Collect image files\n",
    "# ----------------------------\n",
    "all_imgs = sorted(\n",
    "    f for f in nii_root.glob(\"*.nii.gz\")\n",
    "    if f.name.endswith(\"_ch0.nii.gz\") and \"_label\" not in f.name\n",
    ")\n",
    "\n",
    "print(f\"Found {len(all_imgs)} patches\")\n",
    "if len(all_imgs) < 4:\n",
    "    raise RuntimeError(\"Need at least 4 patches.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Deterministic split\n",
    "# ----------------------------\n",
    "random.Random(123).shuffle(all_imgs)\n",
    "\n",
    "n_test = 2\n",
    "n_val = max(1, int(0.2 * (len(all_imgs)-n_test)))\n",
    "\n",
    "test_imgs  = all_imgs[:n_test]\n",
    "val_imgs   = all_imgs[n_test:n_test+n_val]\n",
    "train_imgs = all_imgs[n_test+n_val:]\n",
    "\n",
    "print(f\"Train={len(train_imgs)}  Val={len(val_imgs)}  Test={len(test_imgs)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def load_nifti(path: Path):\n",
    "    arr = nib.load(str(path)).get_fdata()\n",
    "    arr = np.squeeze(arr)\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D but got {arr.shape}\")\n",
    "    return np.transpose(arr, (2, 1, 0))  # XYZ â†’ ZYX\n",
    "\n",
    "def label_path(img: Path):\n",
    "    return img.with_name(img.name.replace(\".nii.gz\", \"_label.nii.gz\"))\n",
    "\n",
    "# ----------------------------\n",
    "# Convert and save\n",
    "# ----------------------------\n",
    "rows = []\n",
    "def convert_split(name, imgs):\n",
    "    vol_dir, lab_dir = splits[name]\n",
    "\n",
    "    for img_path in imgs:\n",
    "        lab_path = label_path(img_path)\n",
    "        if not lab_path.exists():\n",
    "            raise FileNotFoundError(f\"Missing label: {lab_path}\")\n",
    "\n",
    "        img = load_nifti(img_path).astype(np.float32)\n",
    "        lab = load_nifti(lab_path).astype(np.uint8)\n",
    "\n",
    "        base = img_path.name.removesuffix(\".nii.gz\")\n",
    "        out_img = vol_dir / f\"{base}.tif\"\n",
    "        out_lab = lab_dir / f\"{base}_label.tif\"\n",
    "\n",
    "        tiff.imwrite(out_img, img)\n",
    "        tiff.imwrite(out_lab, lab)\n",
    "\n",
    "        rows.append({\n",
    "            \"split\": name,\n",
    "            \"nii_image\": str(img_path),\n",
    "            \"nii_label\": str(lab_path),\n",
    "            \"tif_image\": str(out_img),\n",
    "            \"tif_label\": str(out_lab),\n",
    "        })\n",
    "\n",
    "convert_split(\"train\", train_imgs)\n",
    "convert_split(\"val\",   val_imgs)\n",
    "convert_split(\"test\",  test_imgs)\n",
    "\n",
    "# Save CSV\n",
    "csv_path = base_out / \"splits_cell_nucleus.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, rows[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(\"Saved split info â†’\", csv_path)\n",
    "print(\"TIF dataset ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train WNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Starting from pretrained WNet weights.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f891d684b9504ebf8689df167310109a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n",
      "Loading dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 270141.61it/s]\n",
      "`data_array` is not of type `MetaTensor, assuming affine to be identity.\n",
      "Loading dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 36.27it/s]\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "max_pool3d_with_indices_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647327489/work/aten/src/ATen/Context.cpp:91.)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 77.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.20it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.79it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.37it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.37it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.37it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.20it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.75it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 84.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.79it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.33it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.07it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.81it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.97it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 84.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.75it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.75it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 84.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.96it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.65it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.97it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 84.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.97it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.79it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.97it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 84.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 84.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.65it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.81it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 84.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 88.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.79it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 68.97it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 85.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.97it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 86.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 87.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from napari_cellseg3d.dev_scripts import colab_training as c\n",
    "from napari_cellseg3d.config import WNetTrainingWorkerConfig, WandBConfig, WeightsInfo\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ----------------------------\n",
    "# Training paths\n",
    "# ----------------------------\n",
    "train_vol = tif_root / \"train\" / \"vol\"\n",
    "val_vol   = tif_root / \"val\" / \"vol\"\n",
    "val_lab   = tif_root / \"val\" / \"lab\"\n",
    "save_dir  = base_out / \"checkpoints\"\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Training hyperparameters\n",
    "# ----------------------------\n",
    "num_epochs = 50\n",
    "validation_freq = 2\n",
    "\n",
    "batch_size = 4\n",
    "learning_rate = 2e-5\n",
    "num_classes = 2\n",
    "weight_decay = 0.01\n",
    "\n",
    "# Tell CellSeg3D to start from the built-in WNet pretrained weights\n",
    "pretrained_wnet_weights = WeightsInfo(\n",
    "    use_pretrained=True,   # <- start from pretrained WNet\n",
    "    use_custom=False,      # <- not using a custom checkpoint for training\n",
    "    path=None,             # or \"\" â€“ path is only needed for custom weights\n",
    ")\n",
    "\n",
    "\n",
    "# Tell CellSeg3D to start from the built-in WNet pretrained weights\n",
    "pretrained_wnet_weights = WeightsInfo(\n",
    "    use_pretrained=True,\n",
    "    use_custom=False,\n",
    "    path=None,\n",
    ")\n",
    "\n",
    "train_config = WNetTrainingWorkerConfig(\n",
    "    device=\"cuda:0\",\n",
    "    max_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    validation_interval=validation_freq,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    "    weights_info=pretrained_wnet_weights,   # <- using WNet pretrained weights\n",
    "    results_path_folder=str(save_dir),\n",
    "    train_data_dict=c.create_dataset_dict_no_labs(train_vol),\n",
    "    eval_volume_dict=c.create_eval_dataset_dict(val_vol, val_lab),\n",
    "\n",
    "    # Advanced parameters:\n",
    "    num_classes=num_classes,\n",
    "    weight_decay=weight_decay,\n",
    "    intensity_sigma=1.0,\n",
    "    spatial_sigma=4.0,\n",
    "    radius=2,\n",
    "    reconstruction_loss=\"MSE\",\n",
    "    n_cuts_weight=0.5,\n",
    "    rec_loss_weight=0.005,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "twcfg = train_config\n",
    "winfo = twcfg.weights_info\n",
    "\n",
    "if getattr(winfo, \"use_custom\", False) and getattr(winfo, \"path\", None):\n",
    "    print(f\"[Train] Using custom weights from: {winfo.path}\")\n",
    "elif getattr(winfo, \"use_pretrained\", False):\n",
    "    print(\"[Train] Starting from pretrained WNet weights.\")\n",
    "else:\n",
    "    print(\"[Train] Starting from random init weights.\")\n",
    "\n",
    "\n",
    "\n",
    "wandb_config = WandBConfig(mode=\"disabled\")\n",
    "\n",
    "worker = c.get_colab_worker(worker_config=train_config, wandb_config=wandb_config)\n",
    "\n",
    "# ----------------------------\n",
    "# Training loop with live losses\n",
    "# ----------------------------\n",
    "training_gen = worker.train()\n",
    "\n",
    "pbar = tqdm(total=num_epochs, desc=\"Training\", unit=\"epoch\")\n",
    "prev_epochs = 0\n",
    "\n",
    "for _ in training_gen:\n",
    "    epochs_done = len(worker.total_losses)\n",
    "\n",
    "    if epochs_done > prev_epochs:\n",
    "        prev_epochs = epochs_done\n",
    "        idx = epochs_done\n",
    "\n",
    "        train_loss = worker.total_losses[-1]\n",
    "        rec_loss   = worker.rec_losses[-1]\n",
    "        ncuts_loss = worker.ncuts_losses[-1]\n",
    "\n",
    "        postfix = {\n",
    "            \"train\": f\"{train_loss:.4f}\",\n",
    "            \"rec\":   f\"{rec_loss:.4f}\",\n",
    "            \"ncuts\": f\"{ncuts_loss:.4f}\",\n",
    "        }\n",
    "\n",
    "        if worker.dice_values:\n",
    "            postfix[\"val_dice\"] = f\"{worker.dice_values[-1]:.4f}\"\n",
    "\n",
    "        pbar.set_description(f\"Epoch {idx}\")\n",
    "        pbar.set_postfix(postfix)\n",
    "        pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CellSeg3D] Using FINETUNED custom weights from: /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints/wnet_best_metric.pth\n",
      "Processing patch_004_vol004_ch0.tif\n",
      "--------------------\n",
      "Parameters summary :\n",
      "Model is : WNet3D\n",
      "Window inference is enabled\n",
      "Window size is 64\n",
      "Window overlap is 0.25\n",
      "Dataset loaded on cuda device\n",
      "--------------------\n",
      "MODEL DIMS : [64, 64, 64]\n",
      "Model name : WNet3D\n",
      "Instantiating model...\n",
      "Loading weights...\n",
      "Weights status : None\n",
      "Done\n",
      "--------------------\n",
      "Parameters summary :\n",
      "Model is : WNet3D\n",
      "Window inference is enabled\n",
      "Window size is 64\n",
      "Window overlap is 0.25\n",
      "Dataset loaded on cuda device\n",
      "--------------------\n",
      "Loading layer\n",
      "2025-11-28 14:53:15,456 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'function', transform is not lazy\n",
      "2025-11-28 14:53:15,458 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'ToTensor', transform is not lazy\n",
      "2025-11-28 14:53:15,462 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'EnsureType', transform is not lazy\n",
      "Done\n",
      "----------\n",
      "Inference started on layer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Thresholding with 0.4\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Clearing large objects with 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer prediction saved as : volume_WNet3D_pred_1_2025_11_28_14_53_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 12.02it/s]\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Running instance segmentation with 0.55 and 0.55\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Clearing small objects with 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in scalar divide\n",
      "invalid value encountered in scalar multiply\n",
      "WARNING:napari_cellseg3d.utils:0 invalid sphericities were set to NaN. This occurs for objects with a volume of 1 pixel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patch_006_vol006_ch0.tif\n",
      "--------------------\n",
      "Parameters summary :\n",
      "Model is : WNet3D\n",
      "Window inference is enabled\n",
      "Window size is 64\n",
      "Window overlap is 0.25\n",
      "Dataset loaded on cuda device\n",
      "--------------------\n",
      "MODEL DIMS : [64, 64, 64]\n",
      "Model name : WNet3D\n",
      "Instantiating model...\n",
      "Loading weights...\n",
      "Weights status : None\n",
      "Done\n",
      "--------------------\n",
      "Parameters summary :\n",
      "Model is : WNet3D\n",
      "Window inference is enabled\n",
      "Window size is 64\n",
      "Window overlap is 0.25\n",
      "Dataset loaded on cuda device\n",
      "--------------------\n",
      "Loading layer\n",
      "2025-11-28 14:53:16,613 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'function', transform is not lazy\n",
      "2025-11-28 14:53:16,615 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'ToTensor', transform is not lazy\n",
      "2025-11-28 14:53:16,618 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'EnsureType', transform is not lazy\n",
      "Done\n",
      "----------\n",
      "Inference started on layer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Thresholding with 0.4\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Clearing large objects with 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer prediction saved as : volume_WNet3D_pred_1_2025_11_28_14_53_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 14.06it/s]\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Running instance segmentation with 0.55 and 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Clearing small objects with 5\n",
      "WARNING:napari_cellseg3d.utils:0 invalid sphericities were set to NaN. This occurs for objects with a volume of 1 pixel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Predictions saved to /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/preds/test\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tifffile import imread, imwrite\n",
    "from napari_cellseg3d.dev_scripts import remote_inference as cs3d\n",
    "from napari_cellseg3d.config import ModelInfo, WeightsInfo\n",
    "from pathlib import Path\n",
    "\n",
    "test_vol = tif_root / \"test\" / \"vol\"\n",
    "pred_root = base_out / \"preds\" / \"test\"\n",
    "pred_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# load your checkpoint\n",
    "ckpt = save_dir / \"wnet_best_metric.pth\"\n",
    "assert ckpt.exists()\n",
    "\n",
    "# Build inference configuration\n",
    "inference_config = deepcopy(cs3d.CONFIG)\n",
    "inference_config.model_info = ModelInfo(\n",
    "    name=\"WNet3D\",\n",
    "    model_input_size=[64, 64, 64],\n",
    "    num_classes=2,\n",
    ")\n",
    "inference_config.weights_config = WeightsInfo(\n",
    "    path=str(ckpt),\n",
    "    use_pretrained=False,\n",
    "    use_custom=True,\n",
    ")\n",
    "\n",
    "wcfg = inference_config.weights_config\n",
    "\n",
    "if wcfg.use_custom and wcfg.path:\n",
    "    print(f\"[CellSeg3D] Using FINETUNED custom weights from: {wcfg.path}\")\n",
    "elif wcfg.use_pretrained:\n",
    "    print(\"[CellSeg3D] Using pretrained WNet weights (built-in).\")\n",
    "else:\n",
    "    print(\"[CellSeg3D] WARNING: No custom or pretrained weights selected â€“ using random init!\")\n",
    "\n",
    "\n",
    "pp_config = cs3d.PostProcessConfig()\n",
    "\n",
    "def infer_one(vol):\n",
    "    out = cs3d.inference_on_images(vol, config=inference_config)[0]\n",
    "    sem = out.semantic_segmentation\n",
    "    if sem.ndim == 4:\n",
    "        sem = sem[1]   # take nuclei channel\n",
    "    inst, _ = cs3d.post_processing(sem, config=pp_config)\n",
    "    return sem.astype(np.uint8), inst.astype(np.uint16)\n",
    "\n",
    "for vol_path in sorted(test_vol.glob(\"*.tif\")):\n",
    "    print(\"Processing\", vol_path.name)\n",
    "    vol = imread(str(vol_path)).astype(np.float32)\n",
    "    vmin, vmax = vol.min(), vol.max()\n",
    "    vol_norm = (vol - vmin) / (vmax - vmin) if vmax > vmin else vol\n",
    "\n",
    "    sem, inst = infer_one(vol_norm)\n",
    "\n",
    "    base = vol_path.stem\n",
    "    imwrite(pred_root / f\"{base}_semantic.tif\", sem)\n",
    "    imwrite(pred_root / f\"{base}_instances.tif\", inst)\n",
    "\n",
    "print(\"Done! Predictions saved to\", pred_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check to ensure pretrained weights are used correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint value: 2.155968786610174e-06\n",
      "Finetuned model value: 2.155968786610174e-06\n",
      "Match finetuned? : True\n",
      "Random model value: -0.015734711661934853\n",
      "Random equals finetuned? : False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from napari_cellseg3d.code_models.models.wnet.model import WNet\n",
    "\n",
    "# --- 1. Load checkpoint ---\n",
    "ckpt_path = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints/wnet_best_metric.pth\"\n",
    "state_dict = torch.load(ckpt_path)\n",
    "\n",
    "# pick a parameter to compare\n",
    "param_name = \"encoder.conv1.module.0.weight\"\n",
    "\n",
    "# Value inside checkpoint\n",
    "ckpt_val = state_dict[param_name][0,0,0,0,0].item()\n",
    "print(\"Checkpoint value:\", ckpt_val)\n",
    "\n",
    "# --- 2. Instantiate model with correct architecture (matching training) ---\n",
    "model_finetuned = WNet(\n",
    "    in_channels=1,\n",
    "    out_channels=1,   # important!!\n",
    "    num_classes=2,\n",
    "    dropout=0.65,\n",
    ")\n",
    "\n",
    "# Load finetuned weights into the model\n",
    "model_finetuned.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "# Extract the same parameter from the model\n",
    "model_finetuned_val = model_finetuned.encoder.conv1.module[0].weight[0,0,0,0,0].item()\n",
    "print(\"Finetuned model value:\", model_finetuned_val)\n",
    "\n",
    "# Check match between checkpoint and loaded model\n",
    "print(\"Match finetuned? :\", ckpt_val == model_finetuned_val)\n",
    "\n",
    "# --- 3. Create a randomly initialized model for comparison ---\n",
    "model_random = WNet(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    num_classes=2,\n",
    "    dropout=0.65,\n",
    ")\n",
    "\n",
    "# Extract the same parameter from the random model\n",
    "model_random_val = model_random.encoder.conv1.module[0].weight[0,0,0,0,0].item()\n",
    "print(\"Random model value:\", model_random_val)\n",
    "\n",
    "# Check if random model equals finetuned model\n",
    "print(\"Random equals finetuned? :\", model_random_val == model_finetuned_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cellseg3d-env1",
   "language": "python",
   "name": "cellseg3d-env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
