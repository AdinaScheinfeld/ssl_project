{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AdaptiveMotorControlLab/CellSeg3d/blob/main/notebooks/Colab_WNet3D_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTUVNXX7R3Go"
   },
   "source": [
    "# **WNet3D: self-supervised 3D cell segmentation**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is part of the [CellSeg3D project](https://github.com/AdaptiveMotorControlLab/CellSeg3d) in the [Mathis Lab of Adaptive Intelligence](https://www.mackenziemathislab.org/).\n",
    "\n",
    "- ðŸ’œ The foundation of this notebook owes much to the **[ZeroCostDL4Mic](https://github.com/HenriquesLab/ZeroCostDL4Mic)** project and to the **[DeepLabCut](https://github.com/DeepLabCut/DeepLabCut)** team for bringing Colab into scientific open software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmVCksV0EfVT"
   },
   "source": [
    "#**1. Installing dependencies**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "td_vf_pneSak"
   },
   "outputs": [],
   "source": [
    "# #@markdown ##Play to install CellSeg3D and WNet3D dependencies:\n",
    "# !pip install -q napari-cellseg3d\n",
    "# print(\"Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqctRognFGDT"
   },
   "source": [
    "##**1.2 Load key dependencies**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOOhJjkxjXz-",
    "outputId": "8f94416d-a482-4ec6-f980-a728e908d90d"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from pathlib import Path\n",
    "from napari_cellseg3d.dev_scripts import colab_training as c\n",
    "from napari_cellseg3d.config import WNetTrainingWorkerConfig, WandBConfig, WeightsInfo, PRETRAINED_WEIGHTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax-vJAWRwIKi"
   },
   "source": [
    "## Optional - *1.3 Initialize Weights & Biases integration*\n",
    "---\n",
    "If you wish to utilize Weights & Biases (WandB) for monitoring and logging your training session, uncomment and execute the cell below.\n",
    "To enable it, just input your API key in the space provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNgC3awjwb7G"
   },
   "outputs": [],
   "source": [
    "# !pip install -q wandb\n",
    "# import wandb\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi9gRBHFFyX-"
   },
   "source": [
    "# **2. Complete the Colab session**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSU-LYTfFnvF"
   },
   "source": [
    "\n",
    "## **2.1. Check for GPU access**\n",
    "---\n",
    "\n",
    "By default, this session is configured to use Python 3 and GPU acceleration. To verify or adjust these settings:\n",
    "\n",
    "<font size = 4>Navigate to Runtime and select Change the Runtime type.\n",
    "\n",
    "<font size = 4>For Runtime type, ensure it's set to Python 3 (the programming language this program is written in).\n",
    "\n",
    "<font size = 4>Under Accelerator, choose GPU (Graphics Processing Unit).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ie7bXiMgFtPH",
    "outputId": "3276444c-5109-47b4-f507-ea9acaab15ad"
   },
   "outputs": [],
   "source": [
    "#@markdown ##Execute the cell below to verify if GPU access is available.\n",
    "\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "  print('You do not have GPU access.')\n",
    "  print('Did you change your runtime?')\n",
    "  print('If the runtime setting is correct then Google did not allocate a GPU for your session')\n",
    "  print('Expect slow performance. To access GPU try reconnecting later')\n",
    "\n",
    "else:\n",
    "  print('You have GPU access')\n",
    "  !nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_bbk7RAF2yw"
   },
   "source": [
    "## **2.2. Mount Google Drive**\n",
    "---\n",
    "<font size = 4>To integrate this notebook with your personal data, save your data on Google Drive in accordance with the directory structures detailed in Section 0.\n",
    "\n",
    "1. <font size = 4> **Run** the **cell** below and click on the provided link.\n",
    "\n",
    "2. <font size = 4>Log in to your Google account and grant the necessary permissions by clicking 'Allow'.\n",
    "\n",
    "3. <font size = 4>Copy the generated authorization code and paste it into the cell, then press 'Enter'. This grants Colab access to read and write data to your Google Drive.\n",
    "\n",
    "4. <font size = 4> After completion, you can view your data in the notebook. Simply click the Files tab on the top left and select 'Refresh'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsIARCablq1V",
    "outputId": "77ffdbd1-4c89-4a56-e3da-7777a607a328"
   },
   "outputs": [],
   "source": [
    "# # mount user's Google Drive to Google Colab.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6FI22lkQLTv"
   },
   "source": [
    "**<font size = 4> If you cannot see your files, reactivate your session by connecting to your hosted runtime.**\n",
    "\n",
    "\n",
    "<img width=\"40%\" alt =\"Example of image detection with retinanet.\" src=\"https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/connect_to_hosted.png\"><figcaption> Connect to a hosted runtime. </figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkOpxYjaGM0m"
   },
   "source": [
    "# **3. Select your parameters and paths**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65FhTkYlGKRt"
   },
   "source": [
    "## **3.1. Choosing parameters**\n",
    "\n",
    "---\n",
    "\n",
    "### **Paths to the training data and model**\n",
    "\n",
    "* <font size = 4>**`training_source`** specifies the paths to the training data. They must be a single multipage TIF file each\n",
    "\n",
    "* <font size = 4>**`model_save_path`** specifies the directory where the model checkpoints will be saved.\n",
    "\n",
    "<font size = 4>**Tip:** To easily copy paths, navigate to the 'Files' tab, right-click on a folder or file, and choose 'Copy path'.\n",
    "\n",
    "### **Training parameters**\n",
    "\n",
    "* <font size = 4>**`number_of_epochs`** is the number of times the entire training data will be seen by the model. Default: 50\n",
    "\n",
    "* <font size = 4>**`batchs_size`** is the number of image that will be bundled together at each training step. Default: 4\n",
    "\n",
    "* <font size = 4>**`learning_rate`** is the step size of the update of the model's weight. Try decreasing it if the NCuts loss is unstable. Default: 2e-5\n",
    "\n",
    "* <font size = 4>**`num_classes`** is the number of brightness clusters to segment the image in. Try raising it to 3 if you have artifacts or \"halos\" around your cells that have significantly different brightness. Default: 2\n",
    "\n",
    "* <font size = 4>**`weight_decay`** is a regularization parameter used to prevent overfitting. Default: 0.01\n",
    "\n",
    "* <font size = 4>**`validation_frequency`** is the frequency at which the provided evaluation data is used to estimate the model's performance.\n",
    "\n",
    "* <font size = 4>**`intensity_sigma`** is the standard deviation of the feature similarity term. Default: 1\n",
    "\n",
    "* <font size = 4>**`spatial_sigma`** is the standard deviation of the spatial proximity term. Default: 4\n",
    "\n",
    "* <font size = 4>**`ncuts_radius`** is the radius for the NCuts loss computation, in pixels. Default: 2\n",
    "\n",
    "* <font size = 4>**`rec_loss`** is the loss to use for the decoder. Can be Mean Square Error (MSE) or Binary Cross Entropy (BCE). Default : MSE\n",
    "\n",
    "* <font size = 4>**`n_cuts_weight`** is the weight of the NCuts loss in the weighted sum for the backward pass. Default: 0.5\n",
    "* <font size = 4>**`rec_loss_weight`** is the weight of the reconstruction loss. Default: 0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tTSCC6ChGuuA"
   },
   "outputs": [],
   "source": [
    "#@markdown ###Path to the training data:\n",
    "training_source = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/train\" #@param {type:\"string\"}\n",
    "#@markdown ###Path to save the weights (make sure to have enough space in your drive):\n",
    "model_save_path = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints\" #@param {type:\"string\"}\n",
    "#@markdown ---\n",
    "#@markdown ###Perform validation on a test dataset (optional):\n",
    "do_validation = False #@param {type:\"boolean\"}\n",
    "#@markdown ###Path to evaluation data (optional, use if checked above):\n",
    "eval_source = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/val/vol\" #@param {type:\"string\"}\n",
    "eval_target = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/val/lab\" #@param {type:\"string\"}\n",
    "#@markdown ---\n",
    "#@markdown ###Training parameters\n",
    "number_of_epochs = 50 #@param {type:\"number\"}\n",
    "#@markdown ###Default advanced parameters\n",
    "use_default_advanced_parameters = False #@param {type:\"boolean\"}\n",
    "#@markdown <font size = 4>If not, please change:\n",
    "\n",
    "#@markdown <font size = 3>Training parameters:\n",
    "batch_size =  4 #@param {type:\"number\"}\n",
    "learning_rate = 2e-5 #@param {type:\"number\"}\n",
    "num_classes = 2 #@param {type:\"number\"}\n",
    "weight_decay = 0.01 #@param {type:\"number\"}\n",
    "#@markdown <font size = 3>Validation parameters:\n",
    "validation_frequency = 2 #@param {type:\"number\"}\n",
    "#@markdown <font size = 3>SoftNCuts parameters:\n",
    "intensity_sigma = 1.0 #@param {type:\"number\"}\n",
    "spatial_sigma = 4.0 #@param {type:\"number\"}\n",
    "ncuts_radius = 2 #@param {type:\"number\"}\n",
    "#@markdown <font size = 3>Reconstruction loss:\n",
    "rec_loss = \"MSE\" #@param[\"MSE\", \"BCE\"]\n",
    "#@markdown <font size = 3>Weighted sum of losses:\n",
    "n_cuts_weight = 0.5 #@param {type:\"number\"}\n",
    "rec_loss_weight = 0.005 #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtoIo5GcKIXX"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arWhMU6aKsri"
   },
   "source": [
    "# **4. Train the network**\n",
    "---\n",
    "\n",
    "<font size = 4>Important Reminder: Google Colab imposes a maximum session time to prevent extended GPU usage, such as for data mining. Ensure your training duration stays under 12 hours. If your training is projected to exceed this limit, consider reducing the `number_of_epochs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L59J90S_Kva3"
   },
   "source": [
    "## **4.1. Initialize the config**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOgLyUwPjvUX"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "train_data_folder = Path(training_source)\n",
    "results_path = Path(model_save_path)\n",
    "results_path.mkdir(exist_ok=True)\n",
    "eval_image_folder = Path(eval_source)\n",
    "eval_label_folder = Path(eval_target)\n",
    "\n",
    "eval_dict = c.create_eval_dataset_dict(\n",
    "        eval_image_folder,\n",
    "        eval_label_folder,\n",
    "    ) if do_validation else None\n",
    "\n",
    "try:\n",
    "  import wandb\n",
    "  WANDB_INSTALLED = True\n",
    "except ImportError:\n",
    "  WANDB_INSTALLED = False\n",
    "\n",
    "\n",
    "train_config = WNetTrainingWorkerConfig(\n",
    "    device=\"cuda:0\",\n",
    "    max_epochs=number_of_epochs,\n",
    "    learning_rate=2e-5,\n",
    "    validation_interval=2,\n",
    "    batch_size=4,\n",
    "    num_workers=2,\n",
    "    weights_info=WeightsInfo(),\n",
    "    results_path_folder=str(results_path),\n",
    "    train_data_dict=c.create_dataset_dict_no_labs(train_data_folder),\n",
    "    eval_volume_dict=eval_dict,\n",
    ") if use_default_advanced_parameters else WNetTrainingWorkerConfig(\n",
    "    device=\"cuda:0\",\n",
    "    max_epochs=number_of_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    validation_interval=validation_frequency,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    "    weights_info=WeightsInfo(),\n",
    "    results_path_folder=str(results_path),\n",
    "    train_data_dict=c.create_dataset_dict_no_labs(train_data_folder),\n",
    "    eval_volume_dict=eval_dict,\n",
    "    # advanced\n",
    "    num_classes=num_classes,\n",
    "    weight_decay=weight_decay,\n",
    "    intensity_sigma=intensity_sigma,\n",
    "    spatial_sigma=spatial_sigma,\n",
    "    radius=ncuts_radius,\n",
    "    reconstruction_loss=rec_loss,\n",
    "    n_cuts_weight=n_cuts_weight,\n",
    "    rec_loss_weight=rec_loss_weight,\n",
    ")\n",
    "wandb_config = WandBConfig(\n",
    "    mode=\"disabled\" if not WANDB_INSTALLED else \"online\",\n",
    "    save_model_artifact=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idowGpeQPIm2"
   },
   "source": [
    "## **4.2. Start training**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXxKZhGMqguz"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "worker = c.get_colab_worker(worker_config=train_config, wandb_config=wandb_config)\n",
    "for epoch_loss in worker.train():\n",
    "  continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you have trained the model, you will have the weights as a .pth file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapt to Selma data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 image patches\n",
      "Train: 18, Val: 5, Test: 2\n",
      "Saved split info to /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/splits_cell_nucleus.csv\n",
      "Done creating TIF dataset.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tifffile as tiff\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# ----------------------------\n",
    "# Paths\n",
    "# ----------------------------\n",
    "nii_root = Path(\"/midtier/paetzollab/scratch/ads4015/data_selma3d/selma3d_finetune_patches/cell_nucleus_patches\")\n",
    "base_out = Path(\"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning\")\n",
    "tif_root = base_out / \"tif_data\"\n",
    "\n",
    "tif_train_vol = tif_root / \"train\" / \"vol\"\n",
    "tif_train_lab = tif_root / \"train\" / \"lab\"\n",
    "tif_val_vol   = tif_root / \"val\"   / \"vol\"\n",
    "tif_val_lab   = tif_root / \"val\"   / \"lab\"\n",
    "tif_test_vol  = tif_root / \"test\"  / \"vol\"\n",
    "tif_test_lab  = tif_root / \"test\"  / \"lab\"\n",
    "\n",
    "for p in [tif_train_vol, tif_train_lab, tif_val_vol, tif_val_lab, tif_test_vol, tif_test_lab]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Collect all image files\n",
    "# ----------------------------\n",
    "all_imgs = sorted(\n",
    "    f for f in nii_root.glob(\"*.nii.gz\")\n",
    "    if f.name.endswith(\"_ch0.nii.gz\") and \"_label\" not in f.name\n",
    ")\n",
    "\n",
    "print(f\"Found {len(all_imgs)} image patches\")\n",
    "\n",
    "if len(all_imgs) < 4:\n",
    "    raise RuntimeError(\"Need at least 4 patches for 2 test + train/val split.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Deterministic split\n",
    "# ----------------------------\n",
    "seed = 123\n",
    "random.Random(seed).shuffle(all_imgs)\n",
    "\n",
    "n_total = len(all_imgs)\n",
    "n_test = 2\n",
    "n_trainval = n_total - n_test\n",
    "n_val = max(1, int(round(0.2 * n_trainval)))\n",
    "n_train = n_trainval - n_val\n",
    "\n",
    "test_imgs  = all_imgs[:n_test]\n",
    "val_imgs   = all_imgs[n_test:n_test + n_val]\n",
    "train_imgs = all_imgs[n_test + n_val:]\n",
    "\n",
    "print(f\"Train: {len(train_imgs)}, Val: {len(val_imgs)}, Test: {len(test_imgs)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Helper: NIfTI -> np array\n",
    "# ----------------------------\n",
    "def load_nifti(path: Path):\n",
    "    nii = nib.load(str(path))\n",
    "    arr = nii.get_fdata()\n",
    "    arr = np.squeeze(arr)  # drop singleton channel if present\n",
    "\n",
    "    # NIfTI is typically (X, Y, Z); for TIFF stacks we want (Z, Y, X)\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D volume for {path}, got shape {arr.shape}\")\n",
    "\n",
    "    # reorder axes: (X, Y, Z) -> (Z, Y, X)\n",
    "    arr = np.transpose(arr, (2, 1, 0))\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def img_to_label_path(img_path: Path) -> Path:\n",
    "    # patch_000_vol003_ch0.nii.gz -> patch_000_vol003_ch0_label.nii.gz\n",
    "    return img_path.with_name(img_path.name.replace(\".nii.gz\", \"_label.nii.gz\"))\n",
    "\n",
    "# ----------------------------\n",
    "# Convert and save\n",
    "# ----------------------------\n",
    "rows = []  # to record splits\n",
    "\n",
    "def process_split(split_name, img_paths, vol_dir, lab_dir):\n",
    "    for img_path in img_paths:\n",
    "        lab_path = img_to_label_path(img_path)\n",
    "        if not lab_path.exists():\n",
    "            raise FileNotFoundError(f\"Missing label for {img_path}: {lab_path}\")\n",
    "\n",
    "        img = load_nifti(img_path)\n",
    "        lab = load_nifti(lab_path)\n",
    "\n",
    "        # cast image to float32 so ITK can read it (no 64-bit samples)\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        # cast label to uint8 (0/1 or small integers)\n",
    "        lab = lab.astype(np.uint8)\n",
    "\n",
    "        # properly strip \".nii.gz\"\n",
    "        base_name = img_path.name.replace(\".nii.gz\", \"\")  # -> \"patch_004_vol004_ch0\"\n",
    "\n",
    "        out_img_path = vol_dir / f\"{base_name}.tif\"\n",
    "        out_lab_path = lab_dir / f\"{base_name}_label.tif\"\n",
    "\n",
    "        tiff.imwrite(out_img_path, img)\n",
    "        tiff.imwrite(out_lab_path, lab)\n",
    "\n",
    "\n",
    "        rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"nii_image\": str(img_path),\n",
    "            \"nii_label\": str(lab_path),\n",
    "            \"tif_image\": str(out_img_path),\n",
    "            \"tif_label\": str(out_lab_path),\n",
    "        })\n",
    "\n",
    "process_split(\"train\", train_imgs, tif_train_vol, tif_train_lab)\n",
    "process_split(\"val\",   val_imgs,   tif_val_vol,   tif_val_lab)\n",
    "process_split(\"test\",  test_imgs,  tif_test_vol,  tif_test_lab)\n",
    "\n",
    "# ----------------------------\n",
    "# Save split info\n",
    "# ----------------------------\n",
    "split_csv = base_out / \"splits_cell_nucleus.csv\"\n",
    "with open(split_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"split\", \"nii_image\", \"nii_label\", \"tif_image\", \"tif_label\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved split info to {split_csv}\")\n",
    "print(\"Done creating TIF dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from napari_cellseg3d.dev_scripts import colab_training as c\n",
    "from napari_cellseg3d.config import WNetTrainingWorkerConfig, WandBConfig, WeightsInfo\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Use the TIF dataset we just created\n",
    "# ------------------------------------------------------------------\n",
    "# training_source is the folder with multipage TIF volumes (no labels)\n",
    "training_source = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/tif_data/train/vol\"\n",
    "\n",
    "# model_save_path: where to store training results and checkpoints\n",
    "model_save_path = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints\"\n",
    "\n",
    "# We'll use the val split for in-training validation\n",
    "do_validation = True\n",
    "eval_source = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/tif_data/val/vol\"\n",
    "eval_target = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/tif_data/val/lab\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Training hyperparameters\n",
    "# ------------------------------------------------------------------\n",
    "number_of_epochs = 50\n",
    "\n",
    "use_default_advanced_parameters = False  # we'll set explicitly\n",
    "\n",
    "batch_size = 4\n",
    "learning_rate = 2e-5\n",
    "num_classes = 2            # nuclei vs background\n",
    "weight_decay = 0.01\n",
    "\n",
    "validation_frequency = 2   # validate every 2 epochs\n",
    "\n",
    "# SoftNCuts parameters\n",
    "intensity_sigma = 1.0\n",
    "spatial_sigma = 4.0\n",
    "ncuts_radius = 2\n",
    "\n",
    "# Reconstruction loss\n",
    "rec_loss = \"MSE\"           # or \"BCE\"\n",
    "\n",
    "# Loss mixing\n",
    "n_cuts_weight = 0.5\n",
    "rec_loss_weight = 0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n",
      "Loading dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 279620.27it/s]\n",
      "Loading dataset:   0%|          | 0/5 [00:00<?, ?it/s]`data_array` is not of type `MetaTensor, assuming affine to be identity.\n",
      "Loading dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 37.59it/s]\n",
      "max_pool3d_with_indices_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647327489/work/aten/src/ATen/Context.cpp:91.)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.81it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.33it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.20it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.42it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 49.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.82it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.79it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.37it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.65it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.07it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.68it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.65it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.79it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.42it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.20it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.42it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.42it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.82it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.42it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 57.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_data_folder = Path(training_source)\n",
    "results_path = Path(model_save_path)\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "eval_image_folder = Path(eval_source)\n",
    "eval_label_folder = Path(eval_target)\n",
    "\n",
    "eval_dict = c.create_eval_dataset_dict(\n",
    "    eval_image_folder,\n",
    "    eval_label_folder,\n",
    ") if do_validation else None\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    WANDB_INSTALLED = True\n",
    "except ImportError:\n",
    "    WANDB_INSTALLED = False\n",
    "\n",
    "# -----------------------------\n",
    "# Build training config\n",
    "# -----------------------------\n",
    "if use_default_advanced_parameters:\n",
    "    train_config = WNetTrainingWorkerConfig(\n",
    "        device=\"cuda:0\",\n",
    "        max_epochs=number_of_epochs,\n",
    "        learning_rate=2e-5,\n",
    "        validation_interval=2,\n",
    "        batch_size=4,\n",
    "        num_workers=2,\n",
    "        weights_info=WeightsInfo(),\n",
    "        results_path_folder=str(results_path),\n",
    "        train_data_dict=c.create_dataset_dict_no_labs(train_data_folder),\n",
    "        eval_volume_dict=eval_dict,\n",
    "    )\n",
    "else:\n",
    "    train_config = WNetTrainingWorkerConfig(\n",
    "        device=\"cuda:0\",\n",
    "        max_epochs=number_of_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        validation_interval=validation_frequency,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=2,\n",
    "        weights_info=WeightsInfo(),\n",
    "        results_path_folder=str(results_path),\n",
    "        train_data_dict=c.create_dataset_dict_no_labs(train_data_folder),\n",
    "        eval_volume_dict=eval_dict,\n",
    "        # advanced parameters:\n",
    "        num_classes=num_classes,\n",
    "        weight_decay=weight_decay,\n",
    "        intensity_sigma=intensity_sigma,\n",
    "        spatial_sigma=spatial_sigma,\n",
    "        radius=ncuts_radius,\n",
    "        reconstruction_loss=rec_loss,\n",
    "        n_cuts_weight=n_cuts_weight,\n",
    "        rec_loss_weight=rec_loss_weight,\n",
    "    )\n",
    "\n",
    "wandb_config = WandBConfig(\n",
    "    mode=\"disabled\" if not WANDB_INSTALLED else \"online\",\n",
    "    save_model_artifact=False,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Start training\n",
    "# -----------------------------\n",
    "worker = c.get_colab_worker(worker_config=train_config, wandb_config=wandb_config)\n",
    "\n",
    "for epoch_loss in worker.train():\n",
    "    # you can print / log epoch_loss here if you want\n",
    "    pass\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference using finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from tifffile import imread, imwrite\n",
    "\n",
    "import torch\n",
    "from napari_cellseg3d.dev_scripts import remote_inference as cs3d\n",
    "from napari_cellseg3d.utils import LOGGER as logger\n",
    "from napari_cellseg3d.config import ModelInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'napari_cellseg3d.config.WeightsInfo'>\n",
      "Help on class WeightsInfo in module napari_cellseg3d.config:\n",
      "\n",
      "class WeightsInfo(builtins.object)\n",
      " |  WeightsInfo(path: Optional[str] = '/home/ads4015/micromamba/envs/cellseg3d-env1/lib/python3.10/site-packages/napari_cellseg3d/code_models/models/pretrained', use_pretrained: Optional[bool] = False, use_custom: Optional[bool] = False) -> None\n",
      " |  \n",
      " |  Class to record params for weights.\n",
      " |  \n",
      " |  Args:\n",
      " |      path (Optional[str]): path to weights\n",
      " |      use_custom (Optional[bool]): whether to use custom weights\n",
      " |      use_pretrained (Optional[bool]): whether to use pretrained weights\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, path: Optional[str] = '/home/ads4015/micromamba/envs/cellseg3d-env1/lib/python3.10/site-packages/napari_cellseg3d/code_models/models/pretrained', use_pretrained: Optional[bool] = False, use_custom: Optional[bool] = False) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'path': typing.Optional[str], 'use_custom': typing....\n",
      " |  \n",
      " |  __dataclass_fields__ = {'path': Field(name='path',type=typing.Optional...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('path', 'use_pretrained', 'use_custom')\n",
      " |  \n",
      " |  path = '/home/ads4015/micromamba/envs/cellseg3d-env1/lib...es/napari_c...\n",
      " |  \n",
      " |  use_custom = False\n",
      " |  \n",
      " |  use_pretrained = False\n",
      "\n",
      "CONFIG: InferenceWorkerConfig(device='cuda', model_info=ModelInfo(name='SwinUNetR', model_input_size=64, num_classes=2), weights_config=WeightsInfo(path='/home/ads4015/micromamba/envs/cellseg3d-env1/lib/python3.10/site-packages/napari_cellseg3d/code_models/models/pretrained', use_pretrained=False, use_custom=False), results_path='/home/ads4015/ssl_project/compare_methods/cellseg3d/results', filetype='.tif', keep_on_cpu=False, compute_stats=False, post_process_config=PostProcessConfig(zoom=Zoom(enabled=False, zoom_values=None), thresholding=Thresholding(enabled=False, threshold_value=0.8), instance=InstanceSegConfig(enabled=False, method=None), artifact_removal=False, artifact_removal_size=500), sliding_window_config=SlidingWindowConfig(window_size=64, window_overlap=0.25), use_crf=False, crf_config=CRFConfig(sa=10, sb=5, sg=1, w1=10, w2=5, n_iters=5), images_filepaths=None, layer=None)\n",
      "CONFIG fields: ['__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'compute_stats', 'crf_config', 'device', 'filetype', 'images_filepaths', 'keep_on_cpu', 'layer', 'model_info', 'post_process_config', 'results_path', 'sliding_window_config', 'use_crf', 'weights_config']\n"
     ]
    }
   ],
   "source": [
    "from napari_cellseg3d.config import WeightsInfo\n",
    "import inspect\n",
    "\n",
    "print(WeightsInfo)\n",
    "help(WeightsInfo)          # see its fields / constructor args\n",
    "\n",
    "print(\"CONFIG:\", cs3d.CONFIG)\n",
    "print(\"CONFIG fields:\", dir(cs3d.CONFIG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved wrapped checkpoint to: /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints/wnet_best_metric_for_inference.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "src = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints/wnet_best_metric.pth\"\n",
    "dst = \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints/wnet_best_metric_for_inference.pth\"\n",
    "\n",
    "raw = torch.load(src, map_location=\"cpu\")\n",
    "\n",
    "# If keys have \"module.\", strip them\n",
    "new_state = OrderedDict()\n",
    "for k, v in raw.items():\n",
    "    new_state[k.replace(\"module.\", \"\")] = v\n",
    "\n",
    "wrapped = {\"state_dict\": new_state}\n",
    "\n",
    "torch.save(wrapped, dst)\n",
    "print(\"Saved wrapped checkpoint to:\", dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Selected OpenCL device: 0x5636d6a89110\n",
      "Using custom weights: /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints/wnet_best_metric_for_inference.pth\n",
      "Test vols: ['patch_004_vol004_ch0.tif', 'patch_006_vol006_ch0.tif']\n",
      "Test labs: ['patch_004_vol004_ch0_label.tif', 'patch_006_vol006_ch0_label.tif']\n",
      "Saving preds under: /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/preds/test\n",
      "Selected model: WNet3D\n",
      "\n",
      "=== Processing patch_004_vol004_ch0.tif ===\n",
      "--------------------\n",
      "Parameters summary :\n",
      "Model is : WNet3D\n",
      "Window inference is enabled\n",
      "Window size is 64\n",
      "Window overlap is 0.25\n",
      "Dataset loaded on cuda device\n",
      "--------------------\n",
      "MODEL DIMS : [64, 64, 64]\n",
      "Model name : WNet3D\n",
      "Instantiating model...\n",
      "Loading weights...\n",
      "Weights status : None\n",
      "Done\n",
      "--------------------\n",
      "Parameters summary :\n",
      "Model is : WNet3D\n",
      "Window inference is enabled\n",
      "Window size is 64\n",
      "Window overlap is 0.25\n",
      "Dataset loaded on cuda device\n",
      "--------------------\n",
      "Loading layer\n",
      "2025-11-26 19:41:39,690 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'function', transform is not lazy\n",
      "2025-11-26 19:41:39,692 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'ToTensor', transform is not lazy\n",
      "2025-11-26 19:41:39,697 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'EnsureType', transform is not lazy\n",
      "Done\n",
      "----------\n",
      "Inference started on layer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Thresholding with 0.4\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Clearing large objects with 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing...\n",
      "Layer prediction saved as : volume_WNet3D_pred_1_2025_11_26_19_41_39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Only one label was provided to `remove_small_objects`. Did you mean to use a boolean array?\n",
      "1it [00:00,  1.16it/s]\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Running instance segmentation with 0.55 and 0.55\n",
      "invalid value encountered in divide\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Clearing small objects with 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 96\n",
      "Warning : no objects were removed\n",
      "  Saved semantic to:  /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/preds/test/patch_004_vol004_ch0_cellseg3d_wnet_semantic.tif\n",
      "  Saved instances to: /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/preds/test/patch_004_vol004_ch0_cellseg3d_wnet_instances.tif\n",
      "\n",
      "=== Processing patch_006_vol006_ch0.tif ===\n",
      "--------------------\n",
      "Parameters summary :\n",
      "Model is : WNet3D\n",
      "Window inference is enabled\n",
      "Window size is 64\n",
      "Window overlap is 0.25\n",
      "Dataset loaded on cuda device\n",
      "--------------------\n",
      "MODEL DIMS : [64, 64, 64]\n",
      "Model name : WNet3D\n",
      "Instantiating model...\n",
      "Loading weights...\n",
      "Weights status : None\n",
      "Done\n",
      "--------------------\n",
      "Parameters summary :\n",
      "Model is : WNet3D\n",
      "Window inference is enabled\n",
      "Window size is 64\n",
      "Window overlap is 0.25\n",
      "Dataset loaded on cuda device\n",
      "--------------------\n",
      "Loading layer\n",
      "2025-11-26 19:41:41,384 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'function', transform is not lazy\n",
      "2025-11-26 19:41:41,385 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'ToTensor', transform is not lazy\n",
      "2025-11-26 19:41:41,389 - INFO - Apply pending transforms - lazy: False, pending: 0, upcoming 'EnsureType', transform is not lazy\n",
      "Done\n",
      "----------\n",
      "Inference started on layer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Thresholding with 0.4\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Clearing large objects with 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing...\n",
      "Layer prediction saved as : volume_WNet3D_pred_1_2025_11_26_19_41_41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 10.69it/s]\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Running instance segmentation with 0.55 and 0.55\n",
      "INFO:napari_cellseg3d.dev_scripts.remote_inference:Clearing small objects with 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in scalar divide\n",
      "invalid value encountered in scalar multiply\n",
      "WARNING:napari_cellseg3d.utils:0 invalid sphericities were set to NaN. This occurs for objects with a volume of 1 pixel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved semantic to:  /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/preds/test/patch_006_vol006_ch0_cellseg3d_wnet_semantic.tif\n",
      "  Saved instances to: /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/preds/test/patch_006_vol006_ch0_cellseg3d_wnet_instances.tif\n",
      "\n",
      "Done! Predictions are in: /midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/preds/test\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 0. Imports\n",
    "# ------------------------------------------------------------\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from tifffile import imread, imwrite\n",
    "\n",
    "import torch\n",
    "import napari_cellseg3d\n",
    "from napari_cellseg3d.dev_scripts import remote_inference as cs3d\n",
    "from napari_cellseg3d.utils import LOGGER as logger\n",
    "from napari_cellseg3d.config import ModelInfo, WeightsInfo\n",
    "\n",
    "# Make CellSeg3D log info-level messages\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    import pyclesperanto as cle\n",
    "    cle.select_device()\n",
    "    print(\"Selected OpenCL device:\", cle.get_device())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Paths\n",
    "# ------------------------------------------------------------\n",
    "test_vol_dir = Path(\n",
    "    \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/tif_data/test/vol\"\n",
    ")\n",
    "test_lab_dir = Path(\n",
    "    \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/tif_data/test/lab\"\n",
    ")\n",
    "\n",
    "pred_root = Path(\n",
    "    \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/preds/test\"\n",
    ")\n",
    "pred_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ckpt_path = Path(\n",
    "    \"/midtier/paetzollab/scratch/ads4015/compare_methods/cellseg3d/finetuning/checkpoints/wnet_best_metric_for_inference.pth\"\n",
    ")\n",
    "print(\"Using custom weights:\", ckpt_path)\n",
    "assert ckpt_path.exists(), \"Checkpoint path does not exist!\"\n",
    "\n",
    "print(\"Test vols:\", [p.name for p in sorted(test_vol_dir.glob('*.tif'))])\n",
    "print(\"Test labs:\", [p.name for p in sorted(test_lab_dir.glob('*.tif'))])\n",
    "print(\"Saving preds under:\", pred_root)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Build inference + post-processing config\n",
    "# ------------------------------------------------------------\n",
    "# Start from the default CONFIG but don't mutate the global one\n",
    "inference_config = deepcopy(cs3d.CONFIG)\n",
    "\n",
    "model_selection = \"WNet3D\"\n",
    "print(f\"Selected model: {model_selection}\")\n",
    "\n",
    "# Tell CellSeg3D which model and patch size to use\n",
    "inference_config.model_info = ModelInfo(\n",
    "    name=model_selection,\n",
    "    model_input_size=[64, 64, 64],  # same as your working example\n",
    "    num_classes=2,                  # nuclei vs background\n",
    ")\n",
    "\n",
    "# Point weights_config to your finetuned checkpoint\n",
    "inference_config.weights_config = WeightsInfo(\n",
    "    path=str(ckpt_path),\n",
    "    use_pretrained=False,\n",
    "    use_custom=True,  # <- IMPORTANT: tell it to use your custom weights\n",
    ")\n",
    "\n",
    "# Post-processing config (thresholding + instance seg)\n",
    "post_process_config = cs3d.PostProcessConfig()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Helper: run inference on one volume\n",
    "# ------------------------------------------------------------\n",
    "def run_inference_on_volume(vol_zyx: np.ndarray):\n",
    "    \"\"\"\n",
    "    vol_zyx: np.ndarray with shape (Z, Y, X), float32, ideally in [0, 1].\n",
    "    Returns:\n",
    "        semantic_zyx (uint8)\n",
    "        instance_zyx (uint16)\n",
    "    \"\"\"\n",
    "    # Run the model\n",
    "    result_list = cs3d.inference_on_images(vol_zyx, config=inference_config)\n",
    "    result = result_list[0]\n",
    "\n",
    "    # For WNet3D, semantic output is often (C, Z, Y, X); channel 1 = nuclei\n",
    "    semantic = result.semantic_segmentation\n",
    "    if model_selection == \"WNet3D\" and semantic.ndim == 4:\n",
    "        semantic = semantic[1]  # select nuclei channel -> (Z, Y, X)\n",
    "\n",
    "    # Post-process to instance segmentation\n",
    "    instance_seg, _stats = cs3d.post_processing(\n",
    "        semantic,\n",
    "        config=post_process_config,\n",
    "    )\n",
    "\n",
    "    semantic = semantic.astype(np.uint8)\n",
    "    instance_seg = instance_seg.astype(np.uint16)\n",
    "    return semantic, instance_seg\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Loop over test volumes and save predictions\n",
    "# ------------------------------------------------------------\n",
    "for vol_path in sorted(test_vol_dir.glob(\"*.tif\")):\n",
    "    print(f\"\\n=== Processing {vol_path.name} ===\")\n",
    "\n",
    "    # Load volume as (Z, Y, X)\n",
    "    vol = imread(str(vol_path)).astype(np.float32)\n",
    "\n",
    "    # Match your earlier normalization: scale to [0, 1]\n",
    "    vmin, vmax = vol.min(), vol.max()\n",
    "    if vmax > vmin:\n",
    "        vol_norm = (vol - vmin) / (vmax - vmin)\n",
    "    else:\n",
    "        vol_norm = vol\n",
    "\n",
    "    # Run inference\n",
    "    semantic_zyx, instance_zyx = run_inference_on_volume(vol_norm)\n",
    "\n",
    "    # Output filenames\n",
    "    base = vol_path.stem  # e.g. \"patch_004_vol004_ch0\"\n",
    "    out_sem = pred_root / f\"{base}_cellseg3d_wnet_semantic.tif\"\n",
    "    out_inst = pred_root / f\"{base}_cellseg3d_wnet_instances.tif\"\n",
    "\n",
    "    imwrite(out_sem, semantic_zyx)\n",
    "    imwrite(out_inst, instance_zyx)\n",
    "\n",
    "    print(\"  Saved semantic to: \", out_sem)\n",
    "    print(\"  Saved instances to:\", out_inst)\n",
    "\n",
    "print(\"\\nDone! Predictions are in:\", pred_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "monai-env1",
   "language": "python",
   "name": "monai-env1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
